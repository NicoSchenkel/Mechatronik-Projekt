{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from joblib import load\n",
    "from function_ObjDet  import getObject\n",
    "from dimensionYolo import getObjectDimension \n",
    "#from robotiq3f_py.robotiqcontrol.GripperController import GripperController \n",
    "#from cam import cama\n",
    "#from depthTracking import closing\n",
    "#from depthTracking import gripTrigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Information for predicting size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = ['Basic', 'Pinch', 'Wide', 'Scissor']\n",
    "loaded_rfc = load('random_forest_model76.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyrealsense2.pyrealsense2.pipeline at 0x238ade24270>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)  # bgr is compatible with OpenCV\n",
    "#pipeline.start(config)\n",
    "pipelineProfile = pipeline.start(config)\n",
    "# Align Frames to each other\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_sensor = pipelineProfile.get_device().first_depth_sensor()\n",
    "# Set high accuracy mode\n",
    "depth_sensor = pipelineProfile.get_device().first_depth_sensor()\n",
    "depth_sensor.set_option(rs.option.visual_preset, rs.rs400_visual_preset.high_accuracy)\n",
    "depth_scale = depth_sensor.get_depth_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No stable object detected.\n"
     ]
    }
   ],
   "source": [
    "a = getObjectDimension(pipeline, depth_scale, align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getObject() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get Data for model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mgetObject\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: getObject() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "# Get Data for model\n",
    "a = getObject(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhersage: Basic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicos\\OneDrive\\Desktop\\Mechatronik-Projekt\\Code\\git\\git10\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\nicos\\AppData\\Local\\Temp\\ipykernel_3168\\3037824849.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions = int(loaded_rfc.predict(dataToPredict))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[306.0, 209.5, 0.294]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process Data for Model\n",
    "Objdata = [[a[0][1], a[0][2], a[0][3]]]  # Change this in code of Object Detection!\n",
    "dataToPredict = np.array(Objdata)\n",
    "# Get prediction\n",
    "predictions = int(loaded_rfc.predict(dataToPredict))\n",
    "\n",
    "print(\"Vorhersage:\", mode[predictions])\n",
    "Objdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gripper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for simple usasge\n",
    "transform data in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gripperPos(pos):\n",
    "    gripperPos = [pos]*3 \n",
    "    return gripperPos\n",
    "\n",
    "\n",
    "def gripperSpeed(speed):\n",
    "    gripperSpeed = [speed]*3 \n",
    "    return gripperSpeed\n",
    "\n",
    "def gripperForce(force):\n",
    "    gripperForce = [force]*3 \n",
    "    return gripperForce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect with Gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gripper activateError reading data in update_status.\n",
      "\n",
      "Connected\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GripperController object with the IP address of the server\n",
    "gripper = GripperController(\"192.168.1.11\")\n",
    "gripper.activate()\n",
    "print('Connected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands to gripper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting position: Open Gripper in predicted Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set mode to predicted one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pinch'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = 'Pinch'\n",
    "#mode = mode[predictions]\n",
    "mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values to open Gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command sent\n",
      "[76, 76, 76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicos\\OneDrive\\Desktop\\Mechatronik-Projekt\\Code\\git\\robotiq3f_py\\robotiqcontrol\\GripperController.py:104: UserWarning: only first value of 3d vector will be used when not using Individual Control Flag.\n",
      "  warnings.warn(\"only first value of 3d vector will be used when not using Individual Control Flag.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 73, 73]\n",
      "[68, 68, 68]\n",
      "[63, 63, 63]\n",
      "[58, 59, 59]\n",
      "[53, 54, 54]\n",
      "[49, 49, 49]\n",
      "[44, 45, 45]\n",
      "[40, 40, 40]\n",
      "[36, 36, 36]\n",
      "[31, 32, 31]\n",
      "[27, 27, 27]\n",
      "[22, 22, 22]\n",
      "[17, 18, 17]\n",
      "[12, 13, 13]\n",
      "[8, 8, 8]\n",
      "[8, 8, 8]\n",
      "position reached\n"
     ]
    }
   ],
   "source": [
    "# Default for Satrting position to grab object (open)\n",
    "target_position = gripperPos(10)      # Hängt bei 6\n",
    "force = gripperForce(40)\n",
    "'''\n",
    "Force ausprobieren ob das härte des Zudrückens bestimmt -> langsamere Objektdetektion in Finger\n",
    "Wenn ja bei kleinen Objekten weniger force als be großen?\n",
    "'''\n",
    "speed = [40]\n",
    "# Define if individual finger control is required\n",
    "individual_control = False\n",
    "\n",
    "gripper.command_gripper(rPRA=target_position, rSP=speed, rFR=force, rMOD=mode, rICF=individual_control)\n",
    "print('command sent')\n",
    "        # Wait for the gripper to reach the target positions\n",
    "while ([gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position] != target_position):\n",
    "        print([gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position])\n",
    "        time.sleep(0.1)\n",
    "            \n",
    "print('position reached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"target_position: {target_position}\\nspeed: {speed}\\nforce: {force}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "gripper.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close gripper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirement for closing the gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Nicht aus Kamera ausbrechen, sondern drin bleiben und ditanz überpfüfen\n",
    "\n",
    "Wenn kleiner als bestimmter Wert greifer Schlißen\n",
    "'''\n",
    "closeGripper = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Accuracy activated\n"
     ]
    }
   ],
   "source": [
    "#pipelineProfile = pipeline.start(config)\n",
    "device = pipelineProfile.get_device()\n",
    "depthSensor = device.first_depth_sensor()\n",
    "if depthSensor:\n",
    "    depthSensor.set_option(rs.option.visual_preset, rs.rs400_visual_preset.high_accuracy)\n",
    "    print('High Accuracy activated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values to close Gripper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting closing function...\n",
      "Waiting for frames...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Predicting objects...\n",
      "Object 'cell phone' detected closer than 0.2m. Aborting...\n",
      "Closing function finished.\n"
     ]
    }
   ],
   "source": [
    "#pipeline.stop()\n",
    "#pipeline.start(config)\n",
    "closeGripper = closing(pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeGripper = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command sent\n",
      "checking\n"
     ]
    }
   ],
   "source": [
    "if closeGripper:\n",
    "        target_position = [255]*3 # Closing position\n",
    "        \n",
    "        \n",
    "        movement = [300]*3\n",
    "        gripper.command_gripper(rPRA=target_position, rSP=speed, rFR=force, rMOD=mode, rICF=individual_control)\n",
    "        print('command sent')\n",
    "        movement.append([gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position])\n",
    "        i = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        gripper.command_gripper(rPRA=target_position, rSP=speed, rFR=force, rMOD=mode, rICF=individual_control)\n",
    "\n",
    "                # Wait for the gripper to reach the target positions\n",
    "        while ([gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position] != target_position):\n",
    "                \n",
    "                fingerPos = [gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position]\n",
    "                movement[i] = fingerPos\n",
    "                print('checking')\n",
    "                if fingerPos == movement[i-1]:\n",
    "                        movement.append(fingerPos)\n",
    "                if len(movement):\n",
    "                        break\n",
    "                        \n",
    "                else: \n",
    "                        movement[0] = [300]*0\n",
    "                print([gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position])\n",
    "                print('Sleep')\n",
    "                time.sleep(0.1)\n",
    "                #time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait for next instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for next Step\n"
     ]
    }
   ],
   "source": [
    "print(\"Ready for next Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Gripper to give Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMit mediapipe hand landmarks checken und wenn an Gripper dann loslassen \\nOder wenn Widerstand gespürt wird?\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Mit mediapipe hand landmarks checken und wenn an Gripper dann loslassen \n",
    "Oder wenn Widerstand gespürt wird?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command sent\n",
      "checking\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "target_position = [0]*3 # Closing position\n",
    "movement = [300]*3\n",
    "gripper.command_gripper(rPRA=target_position, rSP=speed, rFR=force, rMOD=mode, rICF=individual_control)\n",
    "print('command sent')\n",
    "movement.append([gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position])\n",
    "i = 1\n",
    "\n",
    "        # Wait for the gripper to reach the target positions\n",
    "while ([gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position] != target_position):\n",
    "       # while any([gripper.FingerA_Current, gripper.FingerB_Current, gripper.FingerC_Current]) !=0: #probleme mit zugreifen, da bei objekterkennung automatisch gestoppt wird?\n",
    "        # while()\n",
    "        # If no futher movemnt because of object in hand -> stop moving!\n",
    "        fingerPos = [gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position]\n",
    "        movement[i] = fingerPos\n",
    "        print('checking')\n",
    "        if fingerPos == movement[i-1]:\n",
    "                movement.append(fingerPos)\n",
    "        if len(movement):\n",
    "                break\n",
    "                \n",
    "        else: \n",
    "                movement[0] = [300]*0\n",
    "        print([gripper.FingerA_Position, gripper.FingerB_Position, gripper.FingerC_Position])\n",
    "        print('Sleep')\n",
    "        time.sleep(0.1)\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stop() cannot be called before start()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      2\u001b[0m gripper\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stop() cannot be called before start()"
     ]
    }
   ],
   "source": [
    "pipeline.stop() \n",
    "gripper.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
